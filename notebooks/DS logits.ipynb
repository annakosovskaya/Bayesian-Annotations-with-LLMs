{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from pathlib import Path\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "from numpyro.ops.indexing import Vindex\n",
    "from tqdm import tqdm\n",
    "from numpyro.handlers import mask\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: P(0) = 0.998, P(1) = 0.002\n",
      "Example 2: P(0) = 0.998, P(1) = 0.002\n",
      "Example 3: P(0) = 0.980, P(1) = 0.020\n",
      "Example 4: P(0) = 0.005, P(1) = 0.995\n",
      "Example 5: P(0) = 0.626, P(1) = 0.374\n",
      "[[0.99847525 0.00152479]\n",
      " [0.9979493  0.00205074]\n",
      " [0.97997653 0.02002344]\n",
      " [0.00530189 0.99469805]\n",
      " [0.6261242  0.37387583]]\n",
      "[[27.625    21.140625]\n",
      " [26.46875  20.28125 ]\n",
      " [26.703125 22.8125  ]\n",
      " [22.90625  28.140625]\n",
      " [24.015625 23.5     ]]\n"
     ]
    }
   ],
   "source": [
    "def get_class_probabilities(logits_path, tokens_json_path, label_tokens=[\"0\", \"1\"]):\n",
    "    \"\"\"\n",
    "    Computes softmax probabilities for class tokens from LLM logits.\n",
    "\n",
    "    Args:\n",
    "        logits_path (str): Path to .npy file containing logits (N x top_k).\n",
    "        tokens_json_path (str): Path to JSON file mapping logits columns to tokens.\n",
    "        label_tokens (list): List of class token strings, e.g. [\"0\", \"1\"].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (N, 2) with probabilities for class \"0\" and \"1\".\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    logits = np.load(logits_path)\n",
    "    with open(tokens_json_path, \"r\") as f:\n",
    "        token_map = json.load(f)\n",
    "\n",
    "    # Find which columns in logits correspond to the class tokens\n",
    "    label_columns = []\n",
    "    for pos_str, (token, _) in token_map.items():\n",
    "        if token.strip() in label_tokens:\n",
    "            label_columns.append(int(pos_str))\n",
    "\n",
    "    if len(label_columns) != 2:\n",
    "        raise ValueError(f\"Expected 2 class tokens, found {len(label_columns)}: {label_columns}\")\n",
    "\n",
    "    # Extract relevant logits\n",
    "    selected_logits = logits[:, label_columns]\n",
    "\n",
    "    # Softmax function\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Calculate probabilities\n",
    "    probs = softmax(selected_logits)\n",
    "\n",
    "    return selected_logits, probs\n",
    "\n",
    "logits_train, probs_train = get_class_probabilities(\"outputs/train/logits.npy\", \"outputs/train/top_tokens.json\")\n",
    "logits_val, probs_val = get_class_probabilities(\"outputs/val/logits.npy\", \"outputs/val/top_tokens.json\")\n",
    "\n",
    "# Show first 5 examples\n",
    "for i in range(5):\n",
    "    print(f\"Example {i+1}: P(0) = {probs_train[i, 0]:.3f}, P(1) = {probs_train[i, 1]:.3f}\")\n",
    "\n",
    "print(probs_train[:5])\n",
    "print(logits_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA LOADING HELPERS --- #\n",
    "\n",
    "def load_jsonl(file_path, max_items=None):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if max_items is not None and i >= max_items:\n",
    "                break\n",
    "            data.append(eval(line))\n",
    "    return data\n",
    "\n",
    "def create_annotator_mapping(data):\n",
    "    from collections import defaultdict\n",
    "    annotator_positions = defaultdict(set)\n",
    "    for item in data:\n",
    "        for pos, ann in enumerate(item['annotators']):\n",
    "            annotator_positions[ann].add(pos)\n",
    "    annotator_to_positions = {}\n",
    "    current_position = 0\n",
    "    for annotator in sorted(annotator_positions.keys()):\n",
    "        positions = sorted(annotator_positions[annotator])\n",
    "        for pos in positions:\n",
    "            annotator_to_positions[(annotator, pos)] = current_position\n",
    "            current_position += 1\n",
    "    return annotator_to_positions\n",
    "\n",
    "def process_annotations(data, annotator_mapping=None):\n",
    "    if annotator_mapping is None:\n",
    "        annotator_mapping = create_annotator_mapping(data)\n",
    "\n",
    "    total_positions = max(annotator_mapping.values()) + 1\n",
    "    positions = np.zeros(total_positions, dtype=int)\n",
    "    annotations = np.zeros((len(data), total_positions), dtype=int)\n",
    "    masks = np.zeros((len(data), total_positions), dtype=bool)\n",
    "\n",
    "    for item_idx, item in enumerate(data):\n",
    "        for pos, (annotator, label) in enumerate(zip(item['annotators'], item['labels'])):\n",
    "            if (annotator, pos) in annotator_mapping:\n",
    "                matrix_pos = annotator_mapping[(annotator, pos)]\n",
    "                annotations[item_idx, matrix_pos] = label\n",
    "                masks[item_idx, matrix_pos] = True\n",
    "                positions[matrix_pos] = annotator\n",
    "    return positions, annotations, masks\n",
    "\n",
    "# as result, matrix annotations with columns meaning (annotator, position) and columns meaning labels for each item on (annotator, position)\n",
    "# positions[i] - who annotated the column i in annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DAWID-SKENE MODEL --- #\n",
    "\n",
    "def dawid_skene(positions, annotations, masks, use_llm_prior=False, llm_probs=None):\n",
    "    num_annotators = int(np.max(positions)) + 1\n",
    "    num_classes = int(np.max(annotations)) + 1\n",
    "    num_items, num_positions = annotations.shape\n",
    "\n",
    "    with numpyro.plate(\"annotator\", num_annotators, dim=-2):\n",
    "        with numpyro.plate(\"class\", num_classes):\n",
    "            beta = numpyro.sample(\"beta\", dist.Dirichlet(jnp.ones(num_classes)))\n",
    "    \n",
    "    if use_llm_prior:\n",
    "        assert llm_probs is not None, \"LLM probabilities must be provided if use_llm_prior is True\"\n",
    "        # pi = numpyro.sample(\"pi\", dist.Dirichlet(llm_probs))\n",
    "        #pi = jnp.asarray(llm_probs)\n",
    "        pi = jnp.array(llm_probs[:,np.newaxis,:])  # shape: (num_items, num_classes)\n",
    "\n",
    "    else:\n",
    "        pi = numpyro.sample(\"pi\", dist.Dirichlet(jnp.ones(num_classes)))\n",
    "\n",
    "    with numpyro.plate(\"item\", num_items, dim=-2):\n",
    "        c = numpyro.sample(\"c\", dist.Categorical(probs=pi), infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        with numpyro.plate(\"position\", num_positions):\n",
    "            with mask(mask=masks):\n",
    "                numpyro.sample(\n",
    "                    \"y\",\n",
    "                    dist.Categorical(Vindex(beta)[positions, c, :]),\n",
    "                    obs=annotations,\n",
    "                )\n",
    "\n",
    "\n",
    "# --- MAIN EXECUTION --- #\n",
    "\n",
    "def run_ds_on_subset(json_path, use_llm_prior=False, llm_probs=None, max_items=None):\n",
    "    data = load_jsonl(json_path, max_items=max_items)\n",
    "    positions, annotations, masks = process_annotations(data)\n",
    "\n",
    "    if use_llm_prior:\n",
    "        if llm_probs is None:\n",
    "            raise ValueError(\"llm_probs must be provided when use_llm_prior=True\")\n",
    "        if len(llm_probs.shape) != 2:\n",
    "            raise ValueError(f\"llm_probs should be 2D array, got shape {llm_probs.shape}\")\n",
    "        if llm_probs.shape[0] < annotations.shape[0]:\n",
    "            raise ValueError(f\"Not enough LLM probabilities for all items: {llm_probs.shape[0]} < {annotations.shape[0]}\")\n",
    "        llm_probs = llm_probs[:annotations.shape[0]]\n",
    "    \n",
    "    kernel = NUTS(dawid_skene)\n",
    "    mcmc = MCMC(kernel, num_warmup=500, num_samples=1000)\n",
    "    mcmc.run(\n",
    "        random.PRNGKey(0),\n",
    "        positions,\n",
    "        annotations,\n",
    "        masks,\n",
    "        use_llm_prior=use_llm_prior,\n",
    "        llm_probs=llm_probs,\n",
    "    )\n",
    "    mcmc.print_summary()\n",
    "\n",
    "    samples = mcmc.get_samples()\n",
    "    beta_mean = jnp.mean(samples['beta'], axis=0)\n",
    "\n",
    "    print(\"\\nInferred confusion matrices (beta) for annotators:\")\n",
    "    for i, matrix in enumerate(beta_mean):\n",
    "        print(f\"Annotator {i}:\\n{np.round(matrix, 2)}\\n\")\n",
    "\n",
    "    predictive = Predictive(dawid_skene, samples, infer_discrete=True)\n",
    "    discrete_samples = predictive(\n",
    "        random.PRNGKey(1),\n",
    "        positions,\n",
    "        annotations,\n",
    "        masks,\n",
    "        use_llm_prior=use_llm_prior,\n",
    "        llm_probs=llm_probs,\n",
    "    )\n",
    "    predicted_labels = discrete_samples[\"c\"]\n",
    "    return samples, predicted_labels, beta_mean\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#    mcmc_samples, predicted_labels, beta_mean = run_ds_on_subset(\"data/ghc_train.jsonl\", use_llm_prior=True, llm_probs=probs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom numpyro.infer import Predictive\\n\\n# train_data = load_jsonl(\"data/ghc_train.jsonl\", max_items=100)\\n# train_positions, train_annotations, train_masks = process_annotations(train_data)\\n\\nval_data = load_jsonl(\"data/ghc_val.jsonl\") #, max_items=100)\\nval_positions, val_annotations, val_masks = process_annotations(val_data)\\n\\ntrain_mcmc_samples, predicted_labels_train, beta_mean_train = run_ds_on_subset(\\n    json_path=\"data/ghc_train.jsonl\",\\n    use_llm_prior=True,\\n    llm_probs=probs_train\\n    )\\n    # max_items=100\\n\\npredictive_val = Predictive(\\n    dawid_skene,\\n    posterior_samples={\"beta\": beta_mean_train[None, ...]},  # making shape (1, annotators, C, C)\\n    infer_discrete=True\\n)\\n\\nprobs_val = probs_val[:val_annotations.shape[0]]\\n\\nval_pred = predictive_val(\\n    random.PRNGKey(1),\\n    val_positions,\\n    val_annotations,\\n    val_masks,\\n    use_llm_prior=True,\\n    llm_probs=probs_val[:val_annotations.shape[0]]\\n)\\n\\nval_predicted_labels = np.array(val_pred[\"c\"]).squeeze()  # shape (num_val_items,)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from numpyro.infer import Predictive\n",
    "\n",
    "# train_data = load_jsonl(\"data/ghc_train.jsonl\", max_items=100)\n",
    "# train_positions, train_annotations, train_masks = process_annotations(train_data)\n",
    "\n",
    "val_data = load_jsonl(\"data/ghc_val.jsonl\") #, max_items=100)\n",
    "val_positions, val_annotations, val_masks = process_annotations(val_data)\n",
    "\n",
    "train_mcmc_samples, predicted_labels_train, beta_mean_train = run_ds_on_subset(\n",
    "    json_path=\"data/ghc_train.jsonl\",\n",
    "    use_llm_prior=True,\n",
    "    llm_probs=probs_train\n",
    "    )\n",
    "    # max_items=100\n",
    "\n",
    "predictive_val = Predictive(\n",
    "    dawid_skene,\n",
    "    posterior_samples={\"beta\": beta_mean_train[None, ...]},  # making shape (1, annotators, C, C)\n",
    "    infer_discrete=True\n",
    ")\n",
    "\n",
    "probs_val = probs_val[:val_annotations.shape[0]]\n",
    "\n",
    "val_pred = predictive_val(\n",
    "    random.PRNGKey(1),\n",
    "    val_positions,\n",
    "    val_annotations,\n",
    "    val_masks,\n",
    "    use_llm_prior=True,\n",
    "    llm_probs=probs_val[:val_annotations.shape[0]]\n",
    ")\n",
    "\n",
    "val_predicted_labels = np.array(val_pred[\"c\"]).squeeze()  # shape (num_val_items,)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1500/1500 [00:05<00:00, 289.04it/s, 7 steps of size 3.39e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      " beta[0,0,0]      0.83      0.12      0.85      0.67      1.00   1557.15      1.00\n",
      " beta[0,0,1]      0.17      0.12      0.15      0.00      0.33   1557.15      1.00\n",
      " beta[0,1,0]      0.30      0.16      0.28      0.02      0.54   1674.09      1.00\n",
      " beta[0,1,1]      0.70      0.16      0.72      0.46      0.98   1674.09      1.00\n",
      " beta[1,0,0]      0.84      0.14      0.89      0.64      1.00   1680.09      1.00\n",
      " beta[1,0,1]      0.16      0.14      0.11      0.00      0.36   1680.09      1.00\n",
      " beta[1,1,0]      0.78      0.18      0.83      0.51      1.00   1747.06      1.00\n",
      " beta[1,1,1]      0.22      0.18      0.17      0.00      0.49   1747.06      1.00\n",
      " beta[2,0,0]      0.83      0.14      0.87      0.64      1.00   1695.99      1.00\n",
      " beta[2,0,1]      0.17      0.14      0.13      0.00      0.36   1695.99      1.00\n",
      " beta[2,1,0]      0.51      0.23      0.52      0.15      0.89   1571.79      1.00\n",
      " beta[2,1,1]      0.49      0.23      0.48      0.11      0.85   1571.79      1.00\n",
      " beta[3,0,0]      0.91      0.08      0.93      0.80      1.00   1619.87      1.00\n",
      " beta[3,0,1]      0.09      0.08      0.07      0.00      0.20   1619.87      1.00\n",
      " beta[3,1,0]      0.43      0.27      0.39      0.02      0.83   1554.25      1.00\n",
      " beta[3,1,1]      0.57      0.27      0.61      0.17      0.98   1554.25      1.00\n",
      " beta[4,0,0]      0.92      0.07      0.94      0.82      1.00   1464.63      1.00\n",
      " beta[4,0,1]      0.08      0.07      0.06      0.00      0.18   1464.63      1.00\n",
      " beta[4,1,0]      0.70      0.24      0.75      0.34      1.00   1197.77      1.00\n",
      " beta[4,1,1]      0.30      0.24      0.25      0.00      0.66   1197.77      1.00\n",
      " beta[5,0,0]      0.74      0.20      0.79      0.43      1.00   1537.35      1.00\n",
      " beta[5,0,1]      0.26      0.20      0.21      0.00      0.57   1537.35      1.00\n",
      " beta[5,1,0]      0.25      0.19      0.20      0.00      0.52   1961.52      1.00\n",
      " beta[5,1,1]      0.75      0.19      0.80      0.48      1.00   1961.52      1.00\n",
      " beta[6,0,0]      0.85      0.09      0.87      0.73      1.00   1588.53      1.00\n",
      " beta[6,0,1]      0.15      0.09      0.13      0.00      0.27   1588.53      1.00\n",
      " beta[6,1,0]      0.41      0.28      0.38      0.00      0.82   1094.96      1.00\n",
      " beta[6,1,1]      0.59      0.28      0.62      0.18      1.00   1094.96      1.00\n",
      " beta[7,0,0]      0.90      0.10      0.92      0.77      1.00   1192.60      1.00\n",
      " beta[7,0,1]      0.10      0.10      0.08      0.00      0.23   1192.60      1.00\n",
      " beta[7,1,0]      0.53      0.16      0.54      0.25      0.79   1615.66      1.00\n",
      " beta[7,1,1]      0.47      0.16      0.46      0.21      0.75   1615.66      1.00\n",
      " beta[8,0,0]      0.93      0.07      0.95      0.83      1.00   2009.38      1.00\n",
      " beta[8,0,1]      0.07      0.07      0.05      0.00      0.17   2009.38      1.00\n",
      " beta[8,1,0]      0.70      0.23      0.75      0.35      1.00   1174.45      1.00\n",
      " beta[8,1,1]      0.30      0.23      0.25      0.00      0.65   1174.45      1.00\n",
      " beta[9,0,0]      0.94      0.04      0.95      0.87      0.99   1534.47      1.00\n",
      " beta[9,0,1]      0.06      0.04      0.05      0.01      0.13   1534.47      1.00\n",
      " beta[9,1,0]      0.63      0.12      0.63      0.44      0.84   1661.83      1.00\n",
      " beta[9,1,1]      0.37      0.12      0.37      0.16      0.56   1661.83      1.00\n",
      "beta[10,0,0]      0.92      0.07      0.94      0.83      1.00   1856.22      1.00\n",
      "beta[10,0,1]      0.08      0.07      0.06      0.00      0.17   1856.22      1.00\n",
      "beta[10,1,0]      0.70      0.24      0.77      0.36      1.00   1225.20      1.00\n",
      "beta[10,1,1]      0.30      0.24      0.23      0.00      0.64   1225.20      1.00\n",
      "beta[11,0,0]      0.95      0.04      0.96      0.89      1.00   1172.88      1.00\n",
      "beta[11,0,1]      0.05      0.04      0.04      0.00      0.11   1172.88      1.00\n",
      "beta[11,1,0]      0.82      0.12      0.85      0.64      0.99   1518.50      1.00\n",
      "beta[11,1,1]      0.18      0.12      0.15      0.01      0.36   1518.50      1.00\n",
      "beta[12,0,0]      0.89      0.10      0.92      0.74      1.00   1366.25      1.00\n",
      "beta[12,0,1]      0.11      0.10      0.08      0.00      0.26   1366.25      1.00\n",
      "beta[12,1,0]      0.86      0.12      0.90      0.68      1.00   1187.29      1.00\n",
      "beta[12,1,1]      0.14      0.12      0.10      0.00      0.32   1187.29      1.00\n",
      "beta[13,0,0]      0.97      0.02      0.98      0.94      1.00   1751.59      1.00\n",
      "beta[13,0,1]      0.03      0.02      0.02      0.00      0.06   1751.59      1.00\n",
      "beta[13,1,0]      0.87      0.07      0.88      0.75      0.97   1968.49      1.00\n",
      "beta[13,1,1]      0.13      0.07      0.12      0.03      0.25   1968.49      1.00\n",
      "beta[14,0,0]      0.66      0.23      0.70      0.31      1.00   1623.54      1.00\n",
      "beta[14,0,1]      0.34      0.23      0.30      0.00      0.69   1623.54      1.00\n",
      "beta[14,1,0]      0.51      0.28      0.52      0.09      0.96   1470.80      1.00\n",
      "beta[14,1,1]      0.49      0.28      0.48      0.04      0.91   1470.80      1.00\n",
      "beta[15,0,0]      0.84      0.15      0.89      0.61      1.00   1833.07      1.00\n",
      "beta[15,0,1]      0.16      0.15      0.11      0.00      0.39   1833.07      1.00\n",
      "beta[15,1,0]      0.62      0.26      0.65      0.21      1.00   1770.30      1.00\n",
      "beta[15,1,1]      0.38      0.26      0.35      0.00      0.79   1770.30      1.00\n",
      "beta[16,0,0]      0.79      0.16      0.83      0.55      1.00   1734.66      1.00\n",
      "beta[16,0,1]      0.21      0.16      0.17      0.00      0.45   1734.66      1.00\n",
      "beta[16,1,0]      0.75      0.20      0.80      0.45      1.00   1811.91      1.00\n",
      "beta[16,1,1]      0.25      0.20      0.20      0.00      0.55   1811.91      1.00\n",
      "beta[17,0,0]      0.92      0.05      0.93      0.85      0.99   2234.82      1.00\n",
      "beta[17,0,1]      0.08      0.05      0.07      0.01      0.15   2234.82      1.00\n",
      "beta[17,1,0]      0.52      0.13      0.52      0.31      0.74   2145.16      1.00\n",
      "beta[17,1,1]      0.48      0.13      0.48      0.26      0.69   2145.16      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "Inferred confusion matrices (beta) for annotators:\n",
      "Annotator 0:\n",
      "[[0.83       0.17      ]\n",
      " [0.29999998 0.7       ]]\n",
      "\n",
      "Annotator 1:\n",
      "[[0.84 0.16]\n",
      " [0.78 0.22]]\n",
      "\n",
      "Annotator 2:\n",
      "[[0.83       0.17      ]\n",
      " [0.51       0.48999998]]\n",
      "\n",
      "Annotator 3:\n",
      "[[0.90999997 0.09      ]\n",
      " [0.42999998 0.57      ]]\n",
      "\n",
      "Annotator 4:\n",
      "[[0.91999996 0.08      ]\n",
      " [0.7        0.29999998]]\n",
      "\n",
      "Annotator 5:\n",
      "[[0.74 0.26]\n",
      " [0.25 0.75]]\n",
      "\n",
      "Annotator 6:\n",
      "[[0.84999996 0.14999999]\n",
      " [0.41       0.59      ]]\n",
      "\n",
      "Annotator 7:\n",
      "[[0.9        0.09999999]\n",
      " [0.53       0.47      ]]\n",
      "\n",
      "Annotator 8:\n",
      "[[0.93       0.07      ]\n",
      " [0.7        0.29999998]]\n",
      "\n",
      "Annotator 9:\n",
      "[[0.94 0.06]\n",
      " [0.63 0.37]]\n",
      "\n",
      "Annotator 10:\n",
      "[[0.91999996 0.08      ]\n",
      " [0.7        0.29999998]]\n",
      "\n",
      "Annotator 11:\n",
      "[[0.95       0.05      ]\n",
      " [0.82       0.17999999]]\n",
      "\n",
      "Annotator 12:\n",
      "[[0.89       0.11      ]\n",
      " [0.85999995 0.14      ]]\n",
      "\n",
      "Annotator 13:\n",
      "[[0.96999997 0.03      ]\n",
      " [0.87       0.13      ]]\n",
      "\n",
      "Annotator 14:\n",
      "[[0.65999997 0.34      ]\n",
      " [0.51       0.48999998]]\n",
      "\n",
      "Annotator 15:\n",
      "[[0.84 0.16]\n",
      " [0.62 0.38]]\n",
      "\n",
      "Annotator 16:\n",
      "[[0.78999996 0.21      ]\n",
      " [0.75       0.25      ]]\n",
      "\n",
      "Annotator 17:\n",
      "[[0.91999996 0.08      ]\n",
      " [0.52       0.48      ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpyro.infer import Predictive\n",
    "from jax import random\n",
    "\n",
    "val_data = load_jsonl(\"data/ghc_val.jsonl\", max_items=100)\n",
    "val_positions, val_annotations, val_masks = process_annotations(val_data)\n",
    "\n",
    "train_mcmc_samples, predicted_labels_train_point_estimate, beta_mean_train = run_ds_on_subset(\n",
    "    json_path=\"data/ghc_train.jsonl\",\n",
    "    use_llm_prior=True,\n",
    "    llm_probs=probs_train,\n",
    "    max_items=100\n",
    ")\n",
    "\n",
    "predictive_for_val_c_samples = Predictive(\n",
    "    dawid_skene,\n",
    "    posterior_samples={'beta': train_mcmc_samples['beta']}, \n",
    "    infer_discrete=True,\n",
    "    return_sites=['c']\n",
    ")\n",
    "\n",
    "# Ensure the correct number of items and 2D shape\n",
    "num_val_items_loaded = val_annotations.shape[0]\n",
    "probs_val_for_pred = probs_val[:num_val_items_loaded]\n",
    "\n",
    "# If probs_val_for_pred happens to be 3D (N, 1, C), squeeze to 2D (N, C)\n",
    "if probs_val_for_pred.ndim == 3 and probs_val_for_pred.shape[1] == 1:\n",
    "    probs_val_for_pred = probs_val_for_pred.squeeze(axis=1)\n",
    "elif probs_val_for_pred.ndim != 2:\n",
    "    raise ValueError(f\"probs_val_for_pred has an unexpected shape: {probs_val_for_pred.shape}, expected 2D.\")\n",
    "\n",
    "val_c_dist_output = predictive_for_val_c_samples(\n",
    "    random.PRNGKey(1),\n",
    "    val_positions,\n",
    "    val_annotations,\n",
    "    val_masks,\n",
    "    use_llm_prior=True,\n",
    "    llm_probs=probs_val_for_pred\n",
    ")\n",
    "\n",
    "c_val_samples = val_c_dist_output[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original c_val_samples shape was (1000, 100, 1), processed to (1000, 100).\n",
      "Calculating accuracy of predicting annotator responses...\n",
      "Using 1000 MCMC samples for c_val.\n",
      "  Processed MCMC samples: 100/1000\n",
      "  Processed MCMC samples: 200/1000\n",
      "  Processed MCMC samples: 300/1000\n",
      "  Processed MCMC samples: 400/1000\n",
      "  Processed MCMC samples: 500/1000\n",
      "  Processed MCMC samples: 600/1000\n",
      "  Processed MCMC samples: 700/1000\n",
      "  Processed MCMC samples: 800/1000\n",
      "  Processed MCMC samples: 900/1000\n",
      "  Processed MCMC samples: 1000/1000\n",
      "Calculation finished.\n",
      "\n",
      "Accuracy of predicting annotator responses on validation: 0.7342\n",
      "(Based on 448000 individual annotator response predictions)\n"
     ]
    }
   ],
   "source": [
    "if 'c_val_samples' not in globals() or 'beta_mean_train' not in globals():\n",
    "    print(\"Error: 'c_val_samples' or 'beta_mean_train' not found.\")\n",
    "    print(\"Please ensure you have run the predictions for 'c' on the validation set (Cell 1) \")\n",
    "    print(\"and have the 'beta_mean_train' from the training phase (from Cell 1).\")\n",
    "else:\n",
    "    if c_val_samples.ndim == 3 and c_val_samples.shape[-1] == 1:\n",
    "        # If shape is (num_samples, num_items, 1), squeeze out the last dimension\n",
    "        c_val_samples_processed = c_val_samples.squeeze(axis=-1)\n",
    "        print(f\"Original c_val_samples shape was {c_val_samples.shape}, processed to {c_val_samples_processed.shape}.\")\n",
    "    elif c_val_samples.ndim == 2:\n",
    "        c_val_samples_processed = c_val_samples\n",
    "        print(f\"c_val_samples shape is {c_val_samples.shape}, using as is.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected shape for c_val_samples: {c_val_samples.shape}. Expected 2D or 3D with last dim 1 (after running Cell 1).\")\n",
    "    \n",
    "    num_mcmc_draws, num_val_items = c_val_samples_processed.shape\n",
    "    \n",
    "    if 'val_annotations' not in globals() or 'val_positions' not in globals() or 'val_masks' not in globals():\n",
    "        print(\"Error: Validation annotation data (val_annotations, val_positions, val_masks) not found.\")\n",
    "    elif val_annotations.shape[0] != num_val_items:\n",
    "         raise ValueError(f\"Number of items in processed c_val_samples ({num_val_items}) \"\n",
    "                          f\"does not match val_annotations ({val_annotations.shape[0]})\")\n",
    "    else:\n",
    "        num_val_items_from_annot, num_positions_in_matrix = val_annotations.shape\n",
    "\n",
    "        correct_predictions_count = 0\n",
    "        total_predictions_made = 0\n",
    "\n",
    "        print(f\"Calculating accuracy of predicting annotator responses...\")\n",
    "        print(f\"Using {num_mcmc_draws} MCMC samples for c_val.\")\n",
    "\n",
    "        # for every \"scenario\" generated\n",
    "        for mcmc_idx in range(num_mcmc_draws):\n",
    "            if (mcmc_idx + 1) % 100 == 0: # Print progress every 100 samples\n",
    "                 print(f\"  Processed MCMC samples: {mcmc_idx + 1}/{num_mcmc_draws}\")\n",
    "\n",
    "            for item_idx in range(num_val_items):\n",
    "                # Get the 'true' label for this item from the current MCMC sample of c\n",
    "                c_true_sample_for_item = c_val_samples_processed[mcmc_idx, item_idx] # Use processed samples\n",
    "\n",
    "                for pos_idx in range(num_positions_in_matrix):\n",
    "                    if val_masks[item_idx, pos_idx]: # If there's an actual annotation\n",
    "                        annotator_id = val_positions[pos_idx]\n",
    "                        actual_annotator_label = val_annotations[item_idx, pos_idx]\n",
    "\n",
    "                        # Probability distribution of this annotator's response P(y_ann | c_true, beta_ann)\n",
    "                        # This is beta_mean_train[annotator_id, c_true_sample_for_item, :]\n",
    "                        prob_dist_annotator_response = beta_mean_train[annotator_id, c_true_sample_for_item, :]\n",
    "\n",
    "                        # Make a hard prediction for this annotator's response\n",
    "                        predicted_annotator_label = jnp.argmax(prob_dist_annotator_response)\n",
    "\n",
    "                        if predicted_annotator_label == actual_annotator_label:\n",
    "                            correct_predictions_count += 1\n",
    "                        total_predictions_made += 1\n",
    "        \n",
    "        print(\"Calculation finished.\")\n",
    "\n",
    "        if total_predictions_made > 0:\n",
    "            accuracy_of_predicting_annotator_responses = correct_predictions_count / total_predictions_made\n",
    "            print(f\"\\nAccuracy of predicting annotator responses on validation: {accuracy_of_predicting_annotator_responses:.4f}\")\n",
    "            print(f\"(Based on {total_predictions_made} individual annotator response predictions)\")\n",
    "        else:\n",
    "            print(\"\\nNo predictions were made for annotator responses.\")\n",
    "            print(\"Check val_masks (perhaps all False) or the number of MCMC samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating fully independent baseline accuracy (LLM priors for 'c', Ideal Annotators)...\n",
      "Fully independent baseline calculation finished.\n",
      "\n",
      "Fully Independent Baseline Accuracy (LLM for 'c', Ideal Beta): 0.6942\n",
      "(Based on 448 individual annotator response predictions)\n"
     ]
    }
   ],
   "source": [
    "# Independent Baseline - LLM priors for 'c' & Ideal Annotators for 'beta'\n",
    "\n",
    "if 'probs_val_for_pred' not in globals(): # LLM priors for validation P(c|item)\n",
    "    print(\"Error: 'probs_val_for_pred' (LLM priors for validation) not found.\")\n",
    "else:\n",
    "    if 'val_annotations' not in globals() or 'val_positions' not in globals() or 'val_masks' not in globals():\n",
    "        print(\"Error: Validation annotation data (val_annotations, val_positions, val_masks) not found.\")\n",
    "    else:\n",
    "        num_val_items_baseline_ideal = probs_val_for_pred.shape[0]\n",
    "        num_classes_baseline_ideal = probs_val_for_pred.shape[1]\n",
    "\n",
    "        if val_annotations.shape[0] != num_val_items_baseline_ideal:\n",
    "            raise ValueError(f\"Number of items in probs_val_for_pred ({num_val_items_baseline_ideal}) \"\n",
    "                             f\"does not match val_annotations ({val_annotations.shape[0]})\")\n",
    "        if num_classes_baseline_ideal != 2:\n",
    "            raise ValueError(f\"Baseline code (ideal annotator) currently assumes num_classes=2, found {num_classes_baseline_ideal}\")\n",
    "\n",
    "        num_val_items_from_annot_baseline_ideal, num_positions_in_matrix_baseline_ideal = val_annotations.shape\n",
    "        \n",
    "        correct_predictions_baseline_ideal_count = 0\n",
    "        total_predictions_baseline_ideal_made = 0\n",
    "\n",
    "        print(f\"\\nCalculating fully independent baseline accuracy (LLM priors for 'c', Ideal Annotators)...\")\n",
    "\n",
    "        # Get hard predictions for 'c' from LLM priors\n",
    "        # c_pred_llm_hard will be 0 or 1 for each item\n",
    "        c_pred_llm_hard = (probs_val_for_pred[:, 1] > 0.5).astype(jnp.int32)\n",
    "\n",
    "        for item_idx in range(num_val_items_baseline_ideal):\n",
    "            # Predicted 'true' label for this item by LLM (hard prediction)\n",
    "            predicted_c_for_item_by_llm = c_pred_llm_hard[item_idx]\n",
    "\n",
    "            for pos_idx in range(num_positions_in_matrix_baseline_ideal):\n",
    "                if val_masks[item_idx, pos_idx]: # If there's an actual annotation\n",
    "                    # annotator_id = val_positions[pos_idx] # Not needed if annotators are ideal\n",
    "                    actual_annotator_label = val_annotations[item_idx, pos_idx]\n",
    "\n",
    "                    # Baseline prediction for annotator's response:\n",
    "                    # If annotators are ideal, they respond with the predicted 'true' label\n",
    "                    predicted_annotator_label_baseline_ideal = predicted_c_for_item_by_llm\n",
    "                    \n",
    "                    if predicted_annotator_label_baseline_ideal == actual_annotator_label:\n",
    "                        correct_predictions_baseline_ideal_count += 1\n",
    "                    total_predictions_baseline_ideal_made += 1\n",
    "        \n",
    "        print(\"Fully independent baseline calculation finished.\")\n",
    "\n",
    "        if total_predictions_baseline_ideal_made > 0:\n",
    "            accuracy_baseline_ideal = correct_predictions_baseline_ideal_count / total_predictions_baseline_ideal_made\n",
    "            print(f\"\\nFully Independent Baseline Accuracy (LLM for 'c', Ideal Beta): {accuracy_baseline_ideal:.4f}\")\n",
    "            print(f\"(Based on {total_predictions_baseline_ideal_made} individual annotator response predictions)\")\n",
    "        else:\n",
    "            print(\"\\nNo predictions were made for the fully independent baseline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In baseline, we get LLM priors and for each text consider the label with higher LLM prior as true label. Then, we think that all annotators are \"ideal\" (vote as true labels are) and by that make predictions for annotators labels. Then, we compare predicted labels of annotators with the real one and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
